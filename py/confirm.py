import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import os
import time
import random
import logging
from tqdm import tqdm

# âœ… æ—¥å¿—é…ç½®ï¼šè¾“å‡ºåˆ°æ§åˆ¶å°ä¸ log æ–‡ä»¶
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("confirm_channel_filter.log"),
        logging.StreamHandler(),
    ],
)

# âœ… é¡¹ç›®é…ç½®ï¼ˆæ ¹æ®ä½ çš„ä»“åº“ä¿®æ”¹ï¼‰
CONFIG = {
    "m3u_url": "https://raw.githubusercontent.com/kfwong15/colection/main/merge.m3u",  # ä½ çš„åˆå¹¶é¢‘é“åˆ—è¡¨
    "save_path": "./merge.m3u",            # æœ¬åœ°ä¿å­˜è·¯å¾„
    "max_workers": 10,                     # å¹¶å‘çº¿ç¨‹æ•°
    "request_timeout": 3,                  # è¯·æ±‚è¶…æ—¶ç§’æ•°
    "random_delay": (0.1, 0.5),            # è¯·æ±‚é—´çš„å»¶è¿ŸèŒƒå›´ï¼ˆé˜²æ­¢é¢‘ç¹è®¿é—®ï¼‰
}

# âœ… æ­¥éª¤ 1ï¼šä¸‹è½½åˆå¹¶é¢‘é“åˆ—è¡¨ï¼ˆmerge.m3uï¼‰
def download_m3u_file(url, save_path):
    try:
        logging.info(f"å¼€å§‹ä¸‹è½½ M3U æ–‡ä»¶: {url}")
        response = requests.get(url)
        response.raise_for_status()
        os.makedirs(os.path.dirname(save_path) or ".", exist_ok=True)
        with open(save_path, "wb") as file:
            file.write(response.content)
        logging.info(f"âœ… ä¸‹è½½å®Œæˆ: {save_path}")
    except requests.exceptions.RequestException as e:
        logging.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        raise

# âœ… æ­¥éª¤ 2ï¼šå»é™¤é‡å¤é¢‘é“å¹¶æ’åº
def remove_duplicates_and_sort(input_file):
    logging.info("ğŸ” å»é™¤é‡å¤é¢‘é“å¹¶æ’åº...")
    channels = {}
    with open(input_file, "r", encoding="utf-8") as file:
        lines = file.readlines()

    i = 0
    while i < len(lines):
        if lines[i].startswith("#EXTINF:"):
            channel_info = lines[i].strip()
            channel_url = lines[i + 1].strip() if i + 1 < len(lines) else ""
            if channel_url not in channels:
                channels[channel_url] = channel_info
            i += 2
        else:
            i += 1

    sorted_channels = sorted(channels.items(), key=lambda x: x[1])

    with open(input_file, "w", encoding="utf-8") as file:
        for url, info in sorted_channels:
            file.write(info + "\n")
            file.write(url + "\n")

    logging.info(f"âœ… å®Œæˆå»é‡æ’åºï¼Œä¿å­˜è‡³: {input_file}")

# âœ… æ­¥éª¤ 3ï¼šæ£€æŸ¥æ¯ä¸ªé¢‘é“æ˜¯å¦èƒ½è®¿é—®
def check_channel_validity(channel_info, channel_url):
    try:
        time.sleep(random.uniform(*CONFIG["random_delay"]))
        response = requests.head(channel_url, timeout=CONFIG["request_timeout"])
        return channel_info, channel_url, response.status_code == 200
    except requests.exceptions.RequestException as e:
        logging.debug(f"â›” é¢‘é“æ£€æµ‹å¤±è´¥: {channel_info} - {e}")
        return channel_info, channel_url, False

# âœ… æ­¥éª¤ 4ï¼šç­›é€‰æœ‰æ•ˆé¢‘é“ï¼Œç§»é™¤åé“¾
def filter_invalid_channels(input_file):
    logging.info("ğŸ§ª å¼€å§‹æ£€æµ‹é¢‘é“é“¾æ¥æ˜¯å¦æœ‰æ•ˆ...")
    with open(input_file, "r", encoding="utf-8") as file:
        lines = file.readlines()

    valid_lines = []
    futures = []

    with ThreadPoolExecutor(max_workers=CONFIG["max_workers"]) as executor:
        for i in range(0, len(lines), 2):
            if i + 1 >= len(lines):
                break
            channel_info = lines[i].strip()
            channel_url = lines[i + 1].strip()
            futures.append(executor.submit(check_channel_validity, channel_info, channel_url))

        for future in tqdm(as_completed(futures), total=len(futures), desc="ğŸ§ª æ£€æŸ¥ä¸­"):
            channel_info, channel_url, is_valid = future.result()
            if is_valid:
                valid_lines.append(channel_info + "\n")
                valid_lines.append(channel_url + "\n")
                logging.info(f"âœ… æœ‰æ•ˆé¢‘é“: {channel_info}")
            else:
                logging.warning(f"âŒ æ— æ•ˆé¢‘é“: {channel_info}")

    with open(input_file, "w", encoding="utf-8") as file:
        file.writelines(valid_lines)

    logging.info("âœ… é¢‘é“è¿‡æ»¤å®Œæˆï¼Œæ–‡ä»¶å·²æ›´æ–°ã€‚")

# âœ… ä¸»ç¨‹åºå…¥å£
def main():
    try:
        download_m3u_file(CONFIG["m3u_url"], CONFIG["save_path"])
        remove_duplicates_and_sort(CONFIG["save_path"])
        filter_invalid_channels(CONFIG["save_path"])
        logging.info("ğŸ‰ æ‰€æœ‰æ­¥éª¤å·²å®Œæˆ")
    except Exception as e:
        logging.error(f"âŒ ç¨‹åºå‡ºé”™: {e}")

if __name__ == "__main__":
    main()
